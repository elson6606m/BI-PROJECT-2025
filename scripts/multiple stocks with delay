import time
import requests
import pandas as pd

def get_stock_data(symbol, api_key):
    url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}&outputsize=full"
    response = requests.get(url)
    data = response.json()

    if "Time Series (Daily)" not in data:
        raise Exception(f"No data returned for {symbol}. Response: {data}")

    df = pd.DataFrame.from_dict(data["Time Series (Daily)"], orient='index')
    df = df.rename(columns={
        "1. open": "open",
        "2. high": "high",
        "3. low": "low",
        "4. close": "close",
        "5. volume": "volume"
    })

    df["symbol"] = symbol
    df.index.name = "date"
    df.reset_index(inplace=True)

    # Convert columns to correct data types
    df["date"] = pd.to_datetime(df["date"])
    df[["open", "high", "low", "close"]] = df[["open", "high", "low", "close"]].astype(float)
    df["volume"] = df["volume"].astype(int)

    return df

# Alpha Vantage API key
api_key = "TKHOK0NCUKX0L35J"

# Stock symbols
symbols = ["AAPL", "GOOGL", "MSFT", "AMZN", "ABNB"]

# Container for all data
all_data = pd.DataFrame()

# Fetch data with delay
for symbol in symbols:
    try:
        df = get_stock_data(symbol, api_key)
        all_data = pd.concat([all_data, df], ignore_index=True)
        print(f"Fetched data for {symbol}")
    except Exception as e:
        print(f"Failed to fetch data for {symbol}: {e}")
    time.sleep(12)  # 12-second delay to avoid rate limits

# Print summary of symbols fetched
print("\nSymbols included in final data:", all_data["symbol"].unique())
print("\nSample data (2 rows per stock):")
print(all_data.groupby("symbol").head(2))

# Optional: Save to CSV
all_data.to_csv("multiple_stocks_data.csv", index=False)
